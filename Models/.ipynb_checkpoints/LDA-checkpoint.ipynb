{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aujourd'hui on roule sur les mecs de l'ENS\n",
    "\n",
    "\n",
    "https://challengedata.ens.fr/en/challenge/39/prediction_of_transaction_claims_status.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports des librairies de bases\n",
    "\n",
    "On ajoutera celles qui manquent au fur et à mesure de nos besoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de la seed pour le random\n",
    "\n",
    "Très important pour qu'on voit les mêmes choses entre nos deux ordis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42;\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des paramètres pour Matplot\n",
    "\n",
    "Rien de bien intéréssant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set des variables globales\n",
    "\n",
    "Attention, je n'utilise les variables globales pour la gestion des fichiers. Sinon, c'est mort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT_DIR, \"data_processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour load les libraires\n",
    "\n",
    "En vrai, on a juste besoin de pd.read_csv, mais c'était pour faire joli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file,data_path=DATA_PROCESSED, sep=';'):\n",
    "    csv_path = os.path.join(data_path, file)\n",
    "    return pd.read_csv(csv_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On load les jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data = load_data(file = \"train.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data.drop(['CARD_PAYMENT','COUPON_PAYMENT','RSP_PAYMENT','WALLET_PAYMENT'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 29 columns):\n",
      "SHIPPING_MODE                 100000 non-null object\n",
      "SHIPPING_PRICE                100000 non-null int64\n",
      "PRICECLUB_STATUS              100000 non-null int64\n",
      "REGISTRATION_DATE             100000 non-null int64\n",
      "PURCHASE_COUNT                100000 non-null int64\n",
      "BUYER_BIRTHDAY_DATE           100000 non-null float64\n",
      "BUYING_DATE                   100000 non-null int64\n",
      "SELLER_SCORE_COUNT            100000 non-null int64\n",
      "SELLER_SCORE_AVERAGE          100000 non-null float64\n",
      "SELLER_COUNTRY                100000 non-null object\n",
      "PRODUCT_TYPE                  100000 non-null object\n",
      "PRODUCT_FAMILY                100000 non-null object\n",
      "ITEM_PRICE                    100000 non-null int64\n",
      "CLAIM_TYPE                    100000 non-null object\n",
      "WARRANTY_COV_RATE             100000 non-null float64\n",
      "SELLER_COUNTRY_PIB            100000 non-null int64\n",
      "SELLER_COUNTRY_DISTANCE       100000 non-null int64\n",
      "BUYER_DEPARTMENT_Life_Lvl     100000 non-null int64\n",
      "SELLER_DEPARTMENT_Life_Lvl    100000 non-null int64\n",
      "BUYER_DEPARTMENT_atk          100000 non-null float64\n",
      "SELLER_DEPARTMENT_atk         100000 non-null float64\n",
      "CAC_POINTS                    100000 non-null int64\n",
      "CAC_VAR                       100000 non-null int64\n",
      "IS_HOLIDAYS                   100000 non-null int64\n",
      "Mean_Claims_Sells_ID          100000 non-null float64\n",
      "STD_Claims_Sells_ID           100000 non-null float64\n",
      "Count_PRODUCT_TYPE            100000 non-null float64\n",
      "Mean_Claims_PRODUCT_TYPE      100000 non-null float64\n",
      "STD_Claims_PRODUCT_TYPE       100000 non-null float64\n",
      "dtypes: float64(10), int64(14), object(5)\n",
      "memory usage: 22.1+ MB\n"
     ]
    }
   ],
   "source": [
    "TX_data.info() # 42 colonnes, c'est un nombre qui fait plaisir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(TX_data, \n",
    "                                       test_size=0.3, \n",
    "                                       random_state=RANDOM_SEED, \n",
    "                                       stratify=TX_data[\"CLAIM_TYPE\"]\n",
    "                                      )\n",
    "del TX_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointure entre les X et Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(data):\n",
    "    data=data.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    # Y and X\n",
    "    try :\n",
    "        Y=data[\"CLAIM_TYPE\"]\n",
    "        X=data.drop(\"CLAIM_TYPE\", axis=1,inplace=False)\n",
    "    except:\n",
    "        Y=0\n",
    "        X=data\n",
    "    # Exclude Objets\n",
    "    X=X.select_dtypes(exclude=['object']) # j'exclude les variables catégorielles que j'ai oublié\n",
    "    \n",
    "    # Work on fare\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imp = Imputer(missing_values='NaN',strategy='median', axis=1)\n",
    "    X=pd.DataFrame(imp.fit_transform(X),columns=X.columns.values)\n",
    " \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = datapreprocess(train_set)\n",
    "X_test, Y_test = datapreprocess(test_set)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(truth, pred):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "    return roc_auc_score(lb.transform(truth), lb.transform(pred), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(matrix):\n",
    "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, X, y, cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XGBoost solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB={\n",
    "# General Parameters -  the overall functioning\n",
    "    'booster':'gbtree',\n",
    "    'silent':0,\n",
    "    #'nthread':4, # Je le commente, puisque il détecte automatiquement le nombre de cores qu'il peut utiliser.\n",
    "    'n_estimators' : 1000,\n",
    "    \n",
    "# Booster Parameters - the individual booster (tree/regression) at each step\n",
    "    'learning_rate' : 0.1,\n",
    "    'min_child_weight' : 1, #A smaller value is chosen because it is a highly imbalanced class problem and leaf nodes can have smaller size groups.\n",
    "    'max_depth' : 3,\n",
    "    #'max_leaf_nodes':None, #If this is defined, GBM will ignore max_depth.\n",
    "    'gamma' : 0.3,\n",
    "    'max_delta_step':4, #it might help in logistic regression when class is extremely imbalanced/ 1-10 might help control the update\n",
    "    'subsample' : 0.55,\n",
    "    'colsample_bytree' : 0.85,\n",
    "    'colsample_bylevel':1, #default\n",
    "    'reg_lambda' : 1, #default\n",
    "    'reg_alpha':0,\n",
    "    'scale_pos_weight' : sample_weight_arr,\n",
    "\n",
    "# Learning Task Parameters -  the optimization performed\n",
    "    'objective' : 'multi:softmax', # you also need to set an additional num_class (number of classes)\n",
    "    'num_class' : len(Y_train.unique()),\n",
    "    'eval_metric':\"auc\",\n",
    "    'seed' : RANDOM_SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(**params_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.85, eval_metric='auc', gamma=0.3,\n",
       "       learning_rate=0.1, max_delta_step=4, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=None, num_class=8, objective='multi:softprob',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=array([ 0.84411,  0.84411, ...,  0.25011,  0.25011]),\n",
       "       seed=42, silent=0, subsample=0.55)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(\n",
    "    X=X_train, \n",
    "    y=Y_train, \n",
    "    sample_weight=sample_weight_arr, \n",
    "    eval_set=None, \n",
    "    eval_metric='auc', \n",
    "    early_stopping_rounds=None, \n",
    "    verbose=True, \n",
    "    xgb_model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_train = xgb_clf.predict(X_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mAUC = multiclass_roc_auc_score(Y_train, y_pred_xgb_train)\n",
    "test_mAUC = multiclass_roc_auc_score(Y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance sur le train : {}\".format(train_mAUC))\n",
    "print(\"Performance sur le test : {}\".format(test_mAUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance sur le train : 0.6589482571844301\n",
    "\n",
    "Performance sur le test : 0.6180906043249655\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx = confusion_matrix(Y_test, y_pred_xgb)\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "plot_confusion_matrix(norm_conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C'est un beau score pour le XBoost\n",
    "\n",
    "Cependant, j'ai optimisé pour la mauvaise métrique, et j'ai toujours pas fait le Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xgb_clf.feature_importances_, index=X_train.columns, columns=[\"Feature\"]).sort_values(by=\"Feature\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Grid Search Iterate\n",
    "\n",
    "Comme mon PC est pourri, je vais chercher les paramètres de façon iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paramètres pour le XGB qui ne changent pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB={\n",
    "# General Parameters -  the overall functioning\n",
    "    'booster':'gbtree',\n",
    "    'silent':0,\n",
    "    #'nthread':4, # Je vais le commenter, puisque il détecte automatiquement le nombre de cores qu'il peut utiliser.\n",
    "    'n_estimators' : 100,\n",
    "    \n",
    "# Booster Parameters - the individual booster (tree/regression) at each step\n",
    "    'learning_rate' : 0.1,\n",
    "    'colsample_bylevel':1, #default\n",
    "    'reg_lambda' : 1, #default\n",
    "    'scale_pos_weight' : sample_weight_arr,\n",
    "\n",
    "# Learning Task Parameters -  the optimization performed\n",
    "    'objective' : 'multi:softmax',\n",
    "    'num_class' : len(Y_train.unique()),\n",
    "    'eval_metric':\"auc\",\n",
    "    'seed' : RANDOM_SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paramètres pour la méthode `fit` de XGB qui ne changent pas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_xgb_cv={\n",
    "    'sample_weight': sample_weight_arr, \n",
    "    'eval_set' : None, \n",
    "    'eval_metric' : 'auc', \n",
    "    'early_stopping_rounds' : None, \n",
    "    'verbose':True, \n",
    "    'xgb_model':None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optim 1 : max_depth, min_child_weight et max_delta_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour le GridSearch\n",
    "params_XGB_CV = {\n",
    "    'max_depth':range(2,5),\n",
    "    'min_child_weight':range(1,6),\n",
    "    'max_delta_step':list(range(1,5)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs_cv = GridSearchCV(XGBClassifier(**params_XGB), \n",
    "                              params_XGB_CV,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs_cv.fit(\n",
    "    X = X_train, \n",
    "    y=Y_train, \n",
    "    groups=None, \n",
    "    **fit_params_xgb_cv\n",
    ")\n",
    "print(xgb_gs_cv.best_estimator_)\n",
    "print(\"ROC score : {}\".format(multiclass_roc_auc_score(Y_test, xgb_gs_cv.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc les paramètres optimaux sont:\n",
    "1. `max_depth` :\n",
    "2. `min_child_weight` :\n",
    "3. `max_delta_step` :\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optim 2 : gamma, et subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour le GridSearch\n",
    "params_XGB_CV = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs_cv = GridSearchCV(XGBClassifier(**params_XGB), \n",
    "                              params_XGB_CV,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs_cv.fit(\n",
    "    X = X_train, \n",
    "    y=Y_train, \n",
    "    groups=None, \n",
    "    **fit_params_xgb_cv\n",
    ")\n",
    "print(xgb_gs_cv.best_estimator_)\n",
    "print(\"ROC score : {}\".format(multiclass_roc_auc_score(Y_test, xgb_gs_cv.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc les paramètres optimaux sont:\n",
    "1. `gamma` :\n",
    "2. `subsample` :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optim 3 : colsample_bytree, et reg_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres pour le GridSearch\n",
    "params_XGB_CV = {\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs_cv = GridSearchCV(XGBClassifier(**params_XGB), \n",
    "                              params_XGB_CV,\n",
    "                              n_jobs=-1,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs_cv.fit(\n",
    "    X = X_train, \n",
    "    y=Y_train, \n",
    "    groups=None, \n",
    "    **fit_params_xgb_cv\n",
    ")\n",
    "print(xgb_gs_cv.best_estimator_)\n",
    "print(\"ROC score : {}\".format(multiclass_roc_auc_score(Y_test, xgb_gs_cv.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc les paramètres optimaux sont:\n",
    "1. `colsample_bytree` :\n",
    "2. `reg_alpha` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx = confusion_matrix(Y_test, y_pred_xgb_cv)\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "plot_confusion_matrix(norm_conf_mx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
