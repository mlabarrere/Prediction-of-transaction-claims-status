{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aujourd'hui on roule sur les mecs de l'ENS\n",
    "\n",
    "\n",
    "https://challengedata.ens.fr/en/challenge/39/prediction_of_transaction_claims_status.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports des librairies de bases\n",
    "\n",
    "On ajoutera celles qui manquent au fur et à mesure de nos besoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de la seed pour le random\n",
    "\n",
    "Très important pour qu'on voit les mêmes choses entre nos deux ordis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42;\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des paramètres pour Matplot\n",
    "\n",
    "Rien de bien intéréssant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set des variables globales\n",
    "\n",
    "Attention, je n'utilise les variables globales pour la gestion des fichiers. Sinon, c'est mort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \"..\"\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT_DIR, \"data_processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour load les libraires\n",
    "\n",
    "En vrai, on a juste besoin de pd.read_csv, mais c'était pour faire joli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file,data_path=DATA_PROCESSED, sep=';'):\n",
    "    csv_path = os.path.join(data_path, file)\n",
    "    return pd.read_csv(csv_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On load les jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data = load_data(file = \"train.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data.drop(['CARD_PAYMENT','COUPON_PAYMENT','RSP_PAYMENT','WALLET_PAYMENT'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 29 columns):\n",
      "SHIPPING_MODE                100000 non-null object\n",
      "SHIPPING_PRICE               100000 non-null int64\n",
      "PRICECLUB_STATUS             100000 non-null int64\n",
      "REGISTRATION_DATE            100000 non-null int64\n",
      "PURCHASE_COUNT               100000 non-null int64\n",
      "BUYER_BIRTHDAY_DATE          100000 non-null float64\n",
      "BUYING_DATE                  100000 non-null int64\n",
      "SELLER_SCORE_COUNT           100000 non-null int64\n",
      "SELLER_SCORE_AVERAGE         100000 non-null float64\n",
      "SELLER_COUNTRY               100000 non-null object\n",
      "PRODUCT_TYPE                 100000 non-null object\n",
      "PRODUCT_FAMILY               100000 non-null object\n",
      "ITEM_PRICE                   100000 non-null int64\n",
      "CLAIM_TYPE                   100000 non-null object\n",
      "WARRANTY_COV_RATE            100000 non-null float64\n",
      "SELLER_COUNTRY_PIB           100000 non-null int64\n",
      "SELLER_COUNTRY_DISTANCE      100000 non-null int64\n",
      "BUYER_DEPARTMENT_DENSITY     100000 non-null int64\n",
      "SELLER_DEPARTMENT_DENSITY    100000 non-null int64\n",
      "BUYER_DEPARTMENT_PIB         100000 non-null int64\n",
      "SELLER_DEPARTMENT_PIB        100000 non-null int64\n",
      "CAC_POINTS                   100000 non-null int64\n",
      "CAC_VAR                      100000 non-null int64\n",
      "IS_HOLIDAYS                  100000 non-null int64\n",
      "Mean_Claims_Sells_ID         100000 non-null float64\n",
      "STD_Claims_Sells_ID          100000 non-null float64\n",
      "Count_PRODUCT_TYPE           100000 non-null float64\n",
      "Mean_Claims_PRODUCT_TYPE     100000 non-null float64\n",
      "STD_Claims_PRODUCT_TYPE      100000 non-null float64\n",
      "dtypes: float64(8), int64(16), object(5)\n",
      "memory usage: 22.1+ MB\n"
     ]
    }
   ],
   "source": [
    "TX_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(TX_data, \n",
    "                                       test_size=0.3, \n",
    "                                       random_state=RANDOM_SEED, \n",
    "                                       stratify=TX_data[\"CLAIM_TYPE\"]\n",
    "                                      )\n",
    "del TX_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointure entre les X et Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(data):\n",
    "    data=data.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    # Y and X\n",
    "    try :\n",
    "        Y=data[\"CLAIM_TYPE\"]\n",
    "        X=data.drop(\"CLAIM_TYPE\", axis=1,inplace=False)\n",
    "    except:\n",
    "        Y=0\n",
    "        X=data\n",
    "    # Exclude Objets\n",
    "    X=X.select_dtypes(exclude=['object'])\n",
    "    \n",
    "    # Work on fare\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imp = Imputer(missing_values='NaN',strategy='median', axis=1)\n",
    "    X=pd.DataFrame(imp.fit_transform(X),columns=X.columns.values)\n",
    " \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = datapreprocess(train_set)\n",
    "X_test, Y_test = datapreprocess(test_set)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(truth, pred):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "    return roc_auc_score(lb.transform(truth), lb.transform(pred), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def plot_confusion_matrix(matrix):\n",
    "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core XGBoost Library VS scikit-learn API\n",
    "\n",
    "Models can be trained in two different ways:\n",
    "\n",
    "1. Directly using the core library – this is closer to the implementation of the caret-package in R\n",
    "2. Using the scikit-learn API – this means that the models are implemented in a way that lets the scikit package recognize it as one of it’s own models.\n",
    "\n",
    "Nous, on va travailler avec l'API de Sklearn, c'est pas optimisé mais plus simple. De toute façon, j'arrive pas à utiliser le Core, a cause des DMatrix qui veulent que des numerics en entrées\n",
    "\n",
    "Doc des paramètres: https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "\n",
    "Doc sur le tunning : https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  XGBoost solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB_balanced={\n",
    "# General Parameters -  the overall functioning\n",
    "    'booster':'gbtree',\n",
    "    'silent':0,\n",
    "    #'nthread':4, # Je le commente, puisque il détecte automatiquement le nombre de cores qu'il peut utiliser.\n",
    "    'n_estimators' : 100,\n",
    "    \n",
    "# Booster Parameters - the individual booster (tree/regression) at each step\n",
    "    'learning_rate' : 0.1,\n",
    "    'min_child_weight' : 10, #A smaller value is chosen because it is a highly imbalanced class problem and leaf nodes can have smaller size groups.\n",
    "    'max_depth' : 5,\n",
    "    #'max_leaf_nodes':None, #If this is defined, GBM will ignore max_depth.\n",
    "    'gamma' : 0.3,\n",
    "    'max_delta_step':0, #it might help in logistic regression when class is extremely imbalanced/ 1-10 might help control the update\n",
    "    'subsample' : 0.55,\n",
    "    'colsample_bytree' : 0.85,\n",
    "    'colsample_bylevel':1, #default\n",
    "    'reg_lambda' : 1, #default\n",
    "    'reg_alpha':0,\n",
    "    'scale_pos_weight' : 1,\n",
    "\n",
    "# Learning Task Parameters -  the optimization performed\n",
    "    'objective' : 'multi:softmax', # you also need to set an additional num_class (number of classes)\n",
    "    'num_class' : len(Y_train.unique()),\n",
    "    'eval_metric':\"auc\",\n",
    "    'seed' : RANDOM_SEED,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(**params_XGB_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-77b32ed7f468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[0;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[0;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[1;32m--> 898\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m    899\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_clf.fit(\n",
    "    X=X_train, \n",
    "    y=Y_train, \n",
    "    #sample_weight=sample_weight_arr, \n",
    "    eval_set=None, \n",
    "    eval_metric='auc', \n",
    "    early_stopping_rounds=None, \n",
    "    verbose=True, \n",
    "    xgb_model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb_train = xgb_clf.predict(X_train)\n",
    "y_pred_xgb = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mAUC = multiclass_roc_auc_score(Y_train, y_pred_xgb_train)\n",
    "test_mAUC = multiclass_roc_auc_score(Y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Performance sur le train : {}\".format(train_mAUC))\n",
    "print(\"Performance sur le test : {}\".format(test_mAUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Non Balanced__:\n",
    "\n",
    "Performance sur le train : 0.6589482571844301\n",
    "\n",
    "Performance sur le test : 0.6180906043249655\n",
    "\n",
    "\n",
    "__Balanced__:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx = confusion_matrix(Y_test, y_pred_xgb)\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "plot_confusion_matrix(norm_conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C'est un beau score pour le XBoost\n",
    "\n",
    "Cependant, j'ai optimisé pour la mauvaise métrique, et j'ai toujours pas fait le Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(xgb_clf.feature_importances_, index=X_train.columns, columns=[\"Feature\"]).sort_values(by=\"Feature\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erreur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.602072530483\n",
      "0.603150318986\n",
      "0.602600104625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, Y_train):\n",
    "    \n",
    "    #Clone du classifier vierge\n",
    "    clone_clf = clone(xgb_clf)\n",
    "    \n",
    "    # Get du X train\n",
    "    X_train_folds = X_train.iloc[train_index]\n",
    "    \n",
    "    # get du Y train\n",
    "    y_train_folds = Y_train.iloc[train_index]\n",
    "    \n",
    "    X_resampled, y_resampled = SMOTE().fit_sample(X_train_folds, y_train_folds)\n",
    "    \n",
    "    X_resampled = pd.DataFrame(X_resampled, columns=X_train_folds.columns)\n",
    "    y_resampled = pd.Series(y_resampled, name=\"CLAIM_TYPE\")\n",
    "    \n",
    "    # get du X test\n",
    "    X_test_fold = X_train.iloc[test_index]\n",
    "    \n",
    "    #Get du Y test\n",
    "    y_test_fold = Y_train.iloc[test_index]\n",
    "\n",
    "    # FIIIIIIT\n",
    "    clone_clf.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    # predict parce que yolo\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    \n",
    "    print(multiclass_roc_auc_score(y_test_fold, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
