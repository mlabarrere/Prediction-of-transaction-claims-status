{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aujourd'hui on roule sur les mecs de l'ENS\n",
    "\n",
    "\n",
    "https://challengedata.ens.fr/en/challenge/39/prediction_of_transaction_claims_status.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports des librairies de bases\n",
    "\n",
    "On ajoutera celles qui manquent au fur et à mesure de nos besoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de la seed pour le random\n",
    "\n",
    "Très important pour qu'on voit les mêmes choses entre nos deux ordis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42;\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des paramètres pour Matplot\n",
    "\n",
    "Rien de bien intéréssant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set des variables globales\n",
    "\n",
    "Attention, je n'utilise les variables globales pour la gestion des fichiers. Sinon, c'est mort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT_DIR, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour load les libraires\n",
    "\n",
    "En vrai, on a juste besoin de pd.read_csv, mais c'était pour faire joli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file,data_path=DATA_PATH, sep=','):\n",
    "    csv_path = os.path.join(data_path, file)\n",
    "    return pd.read_csv(csv_path, sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On load les jeux de données\n",
    "\n",
    "Seulement le train (input_train) pour le moment. Et le \"Y\" des lignes dans le fichier avec le long nom.\n",
    "Je ne sais pas pourquoi ils ont tout divisé, mais peût être pour filter les mecs qui ne savent pas fire des jointures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data = load_data(file = \"input_train.csv\");\n",
    "STA_data = load_data(file = \"challenge_output_data_training_file_prediction_of_transaction_claims_status.csv\", sep=';');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointure entre les X et Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data = pd.merge(TX_data, STA_data, left_index=True, right_index=True)\n",
    "TX_data.drop([\"ID_y\",\"ID_x\"],inplace=True,axis=1)\n",
    "\n",
    "del STA_data #Je supprime toujours les variables inutiles pour liberer ma RAM (qui est très faible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Je laisse ne commentaire les fonctions qui m'ont été utiles pour analyser la BDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data[\"CLAIM_TYPE\"].value_counts().head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction de mise en forme (attention, sportive)\n",
    "\n",
    "Dans la BDD, j'ai vu pas mal de truc du genre \"20<50\", inutilisables. Donc, j'ai voulu splité pour faire une colonne avec le \"20\" (MIN), et une autre avec le \"50\" (MAX).\n",
    "Donc j'ai fait cette fonction qui prend en entrée la BDD, une liste de noms de colones à traiter, et modifie la base de donnée directement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Splitter:\n",
    "    \n",
    "    def __init__(self,list_col):\n",
    "        self.list_work=list_col;\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        X=data.copy()\n",
    "        #X=X[self.list_work]\n",
    "        for colname in self.list_work: # Pour chaque nom de colonne spécifié\n",
    "            toto= data[colname].str.split('<', 1, expand=True) # Split sur le char \"<\" de la colonne. Cette fonction crée 2 colonnes : Une avec ce qu'il y a a gauche du split, une autre à droite\n",
    "            X[colname+\"_MIN\"] = toto[0] # On prend la partie gauche pour faire le MIN\n",
    "            X[colname+\"_MAX\"] = toto[1] # La droite pour le MAX\n",
    "            X[colname+\"_MIN\"]=X[colname+\"_MIN\"].str.replace('>',\"\") # Parfois il y a le signe \">\", donc je le vire simplement\n",
    "            X.drop(colname, axis=1, inplace=True) # Et je drop la colonne inutile maintenant. (Inplace = True veut dire modification de la BDD originale)\n",
    "        #X.replace(\"\", np.nan, inplace=True)\n",
    "        #X.fillna(value=0, inplace=True)\n",
    "        return X;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col_split=[\"WARRANTIES_PRICE\",'SELLER_SCORE_COUNT','ITEM_PRICE','PURCHASE_COUNT','SHIPPING_PRICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=Splitter(list_col=list_col_split)\n",
    "del list_col_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateSplit:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        X=data.copy()\n",
    "        #X=X['BUYING_DATE']\n",
    "        toto= X['BUYING_DATE'].str.split('/', 1, expand=True)\n",
    "        X['BUYING_DATE_Month'] = toto[0]\n",
    "        X['BUYING_DATE_Year'] = toto[1]\n",
    "        X.drop('BUYING_DATE', axis=1, inplace=True)\n",
    "        return X;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là, faut être créatif, et aider l'algorithme à voir des choses, et se focaliser sur d'autres.\n",
    "\n",
    "Je vais rarement drop des colonnes, car à ce moment là, je ne sais pas ce qui est utile ou pas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A une garantie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarrantFlag:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        X=data.copy();\n",
    "        X=X['WARRANTIES_FLG'];\n",
    "        X[\"WARRANTIES_FLG\"] = X[\"WARRANTIES_FLG\"].map({True : 1, False : 0 })\n",
    "        return X;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taux de couverture de la garantie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beaucoup de valeurs en NaN car cela correspond à \"pas de garantie\". \n",
    "# Donc je dis que si il n'y a pas de garantie, elle est à zéro\n",
    "\n",
    "TX_data.WARRANTIES_PRICE_MAX.fillna(value=0, inplace=True)\n",
    "TX_data.WARRANTIES_PRICE_MIN.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarrantCoverage:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass;\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, data):\n",
    "        X=data.copy();\n",
    "        keep_list=[\"WARRANTIES_PRICE_MIN\",\"WARRANTIES_PRICE_MAX\",\"ITEM_PRICE_MIN\",\"ITEM_PRICE_MAX\"]\n",
    "        X=X[keep_list]\n",
    "        \n",
    "        X[\"WARRANTIES_COVERAGE_MIN\"]=X[\"WARRANTIES_PRICE_MIN\"]/(X[\"ITEM_PRICE_MIN\"]+0.1)\n",
    "        X[\"WARRANTIES_COVERAGE_MAX\"]=X[\"WARRANTIES_PRICE_MAX\"]/(X[\"ITEM_PRICE_MAX\"]+0.1)\n",
    "        X.drop(keep_list, axis=1, inplace=True)\n",
    "        return X;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHIPPING_MODE</th>\n",
       "      <th>SHIPPING_PRICE</th>\n",
       "      <th>WARRANTIES_FLG</th>\n",
       "      <th>WARRANTIES_PRICE</th>\n",
       "      <th>CARD_PAYMENT</th>\n",
       "      <th>COUPON_PAYMENT</th>\n",
       "      <th>RSP_PAYMENT</th>\n",
       "      <th>WALLET_PAYMENT</th>\n",
       "      <th>PRICECLUB_STATUS</th>\n",
       "      <th>REGISTRATION_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>BUYER_DEPARTMENT</th>\n",
       "      <th>BUYING_DATE</th>\n",
       "      <th>SELLER_SCORE_COUNT</th>\n",
       "      <th>SELLER_SCORE_AVERAGE</th>\n",
       "      <th>SELLER_COUNTRY</th>\n",
       "      <th>SELLER_DEPARTMENT</th>\n",
       "      <th>PRODUCT_TYPE</th>\n",
       "      <th>PRODUCT_FAMILY</th>\n",
       "      <th>ITEM_PRICE</th>\n",
       "      <th>CLAIM_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>2015</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>3/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>61</td>\n",
       "      <td>CELLPHONE_ACCESSORY</td>\n",
       "      <td>ELECTRONICS</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>DAMAGED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>8/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>30</td>\n",
       "      <td>CELLPHONE_ACCESSORY</td>\n",
       "      <td>ELECTRONICS</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>2013</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>5/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>-1</td>\n",
       "      <td>TOYS</td>\n",
       "      <td>BABY</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>NOT_RECEIVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>5&lt;20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>2007</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>5/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>2</td>\n",
       "      <td>GARDEN_TOOLS</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>50&lt;100</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>2010</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>9/2017</td>\n",
       "      <td>1000&lt;10000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>-1</td>\n",
       "      <td>MODEL</td>\n",
       "      <td>BABY</td>\n",
       "      <td>1000&lt;5000</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  SHIPPING_MODE SHIPPING_PRICE  WARRANTIES_FLG WARRANTIES_PRICE  CARD_PAYMENT  \\\n",
       "0        NORMAL            NaN           False              NaN             1   \n",
       "1        NORMAL            NaN           False              NaN             1   \n",
       "2        NORMAL            NaN           False              NaN             0   \n",
       "3    RECOMMANDE            NaN            True             5<20             1   \n",
       "4    RECOMMANDE            NaN           False              NaN             1   \n",
       "\n",
       "   COUPON_PAYMENT  RSP_PAYMENT  WALLET_PAYMENT PRICECLUB_STATUS  \\\n",
       "0               0            1               0     UNSUBSCRIBED   \n",
       "1               0            0               0     UNSUBSCRIBED   \n",
       "2               0            0               1         PLATINUM   \n",
       "3               0            0               0     UNSUBSCRIBED   \n",
       "4               0            1               0         PLATINUM   \n",
       "\n",
       "   REGISTRATION_DATE      ...      BUYER_DEPARTMENT  BUYING_DATE  \\\n",
       "0               2015      ...                    34       3/2017   \n",
       "1               2013      ...                    77       8/2017   \n",
       "2               2013      ...                    58       5/2017   \n",
       "3               2007      ...                    31       5/2017   \n",
       "4               2010      ...                    93       9/2017   \n",
       "\n",
       "   SELLER_SCORE_COUNT SELLER_SCORE_AVERAGE        SELLER_COUNTRY  \\\n",
       "0        10000<100000                 46.0  FRANCE, METROPOLITAN   \n",
       "1        10000<100000                 45.0  FRANCE, METROPOLITAN   \n",
       "2        10000<100000                 43.0                 CHINA   \n",
       "3        10000<100000                 44.0  FRANCE, METROPOLITAN   \n",
       "4          1000<10000                 44.0                 CHINA   \n",
       "\n",
       "   SELLER_DEPARTMENT         PRODUCT_TYPE  PRODUCT_FAMILY ITEM_PRICE  \\\n",
       "0                 61  CELLPHONE_ACCESSORY     ELECTRONICS        <10   \n",
       "1                 30  CELLPHONE_ACCESSORY     ELECTRONICS        <10   \n",
       "2                 -1                 TOYS            BABY        <10   \n",
       "3                  2         GARDEN_TOOLS           WHITE     50<100   \n",
       "4                 -1                MODEL            BABY  1000<5000   \n",
       "\n",
       "     CLAIM_TYPE  \n",
       "0       DAMAGED  \n",
       "1             -  \n",
       "2  NOT_RECEIVED  \n",
       "3             -  \n",
       "4    WITHDRAWAL  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TX_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import  FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = FeatureUnion([(\"splitter\", split)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>2015</td>\n",
       "      <td>1992</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>2013</td>\n",
       "      <td>1952</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORMAL</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>2013</td>\n",
       "      <td>1991</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td></td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>2007</td>\n",
       "      <td>1955</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>10000</td>\n",
       "      <td>100000</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>500</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>2010</td>\n",
       "      <td>1984</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0      1  2  3  4  5             6     7     8   9  ...    17   18  \\\n",
       "0      NORMAL  False  1  0  1  0  UNSUBSCRIBED  2015  1992  34 ...   NaN  NaN   \n",
       "1      NORMAL  False  1  0  0  0  UNSUBSCRIBED  2013  1952  77 ...   NaN  NaN   \n",
       "2      NORMAL  False  0  0  0  1      PLATINUM  2013  1991  58 ...   NaN  NaN   \n",
       "3  RECOMMANDE   True  1  0  0  0  UNSUBSCRIBED  2007  1955  31 ...     5   20   \n",
       "4  RECOMMANDE  False  1  0  1  0      PLATINUM  2010  1984  93 ...   NaN  NaN   \n",
       "\n",
       "      19      20    21    22   23    24   25   26  \n",
       "0  10000  100000          10          5  NaN  NaN  \n",
       "1  10000  100000          10          5  NaN  NaN  \n",
       "2  10000  100000          10   50   100  NaN  NaN  \n",
       "3  10000  100000    50   100  500  None  NaN  NaN  \n",
       "4   1000   10000  1000  5000    5    20  NaN  NaN  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use combined features to transform dataset:\n",
    "pd.DataFrame(combined_features.transform(TX_data)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is Claim\n",
    "\n",
    "Attention, c'est un peu dangereux d'utiliser la target variable pour faire du feature engineering.\n",
    "\n",
    "Mais ici, je veux créer des \"cartes d'identité\" par vendeur et acheteur, pour reperer les bad guys. Donc je dois connaitre le taux de rejet de chacun. Ce que je vais faire plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui prend une ligne de la BDD en entrée, et dit \"Si c'est - alors on renvoit 0, sinon 1\n",
    "def b(row):\n",
    "        return 0 if row['CLAIM_TYPE'] == '-' else 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je l'applique à la base de données\n",
    "TX_data['IS_CLAIM'] = TX_data.apply(b, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shipping Method\n",
    "\n",
    "Regroupement des méthodes de shipping rares sous la même catégorie.\n",
    "\n",
    "Objectif = Diminuer la complexité de la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data[\"SHIPPING_MODE\"].value_counts().head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rare_delivery_type = ['EXPRESS_DELIVERY',\n",
    "                          'SO_RECOMMANDE',\n",
    "                          'MONDIAL_RELAY',\n",
    "                          'MONDIAL_RELAY_PREPAYE',\n",
    "                          'SO_POINT_RELAIS',\n",
    "                          'CHRONOPOST',\n",
    "                          'PICKUP',\n",
    "                          'Kiala']\n",
    "TX_data[\"SHIPPING_MODE\"].replace(to_replace=list_rare_delivery_type,\n",
    "                                 value=\"RARE_TYPE\",\n",
    "                                 inplace=True)\n",
    "del list_rare_delivery_type;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data = pd.merge(TX_data, \n",
    "                   pd.get_dummies(TX_data[\"SHIPPING_MODE\"]), \n",
    "                   left_index=True, \n",
    "                   right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data.drop(\"SHIPPING_MODE\",\n",
    "             axis=1,\n",
    "             inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Premium\n",
    "\n",
    "Regroupement des types de comptes payant sous la même catégorie.\n",
    "\n",
    "Objectif = Diminuer la complexité de la variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data[\"PRICECLUB_STATUS\"].value_counts().head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_rare_delivery_type= ['PLATINUM', \n",
    "                          'SILVER', \n",
    "                          'GOLD']\n",
    "TX_data[\"PRICECLUB_STATUS\"].replace(to_replace=list_rare_delivery_type, \n",
    "                                 value=\"PREMIUM\", \n",
    "                                 inplace=True)\n",
    "del list_rare_delivery_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data = pd.merge(TX_data, pd.get_dummies(TX_data[\"PRICECLUB_STATUS\"]), left_index=True, right_index=True)\n",
    "TX_data.drop(\"PRICECLUB_STATUS\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajets longs\n",
    "\n",
    "Flag pour signaler un envoi international\n",
    "\n",
    "Objectif = souligner les courts trajets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data[\"SELLER_COUNTRY\"].value_counts().head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(row):\n",
    "    long_haul_list=[\"CHINA\",\"HONG KONG\", \"UNITED STATES\"]\n",
    "    return 1 if row['SELLER_COUNTRY'] in long_haul_list else 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data['LONG_HAUL'] = TX_data.apply(f, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stats par Pays\n",
    "\n",
    "To do : Détecter les pays à problèmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_product_country = TX_data['IS_CLAIM'].groupby(TX_data['SELLER_COUNTRY']).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_country=[\"SELLER_COUNTRY\",\"Count_country\",\"Mean_Claims_country\",\"STD_Claims_country\",\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"]\n",
    "\n",
    "description_product_country.columns = colnames_country\n",
    "description_product_country.drop([\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"], axis=1, inplace=True)\n",
    "description_product_country[\"Count_Claims_country\"] = description_product_country[\"Mean_Claims_country\"] * description_product_country[\"Count_country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data=pd.merge(TX_data, description_product_country, on='SELLER_COUNTRY', how='outer')\n",
    "\n",
    "del description_product_country, colnames_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data.drop(columns=\"SELLER_COUNTRY\" ,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type de produit\n",
    "\n",
    "To do : Détecter les produits fragiles\n",
    "\n",
    "Objectif = souligner cet effet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data[\"PRODUCT_TYPE\"].value_counts().head(10).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_product_type=TX_data['IS_CLAIM'].groupby(TX_data['PRODUCT_TYPE']).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_product_type=[\"PRODUCT_TYPE\",\"Count_product_type\",\"Mean_Claims_product_type\",\"STD_Claims_product_type\",\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"]\n",
    "\n",
    "description_product_type.columns=colnames_product_type\n",
    "description_product_type.drop([\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"],axis=1,inplace=True)\n",
    "description_product_type[\"Count_Claims_product_type\"]=description_product_type[\"Mean_Claims_product_type\"]*description_product_type[\"Count_product_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data=pd.merge(TX_data, description_product_type, on='PRODUCT_TYPE', how='outer')\n",
    "del description_product_type, colnames_product_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data.drop(columns=\"PRODUCT_TYPE\" ,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un ID par client \n",
    "\n",
    "Objectif = créer une base de données client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idBuyerCreator(row):\n",
    "        return hashlib.md5(\n",
    "            (str(row['REGISTRATION_DATE'])+\n",
    "             str(row[\"BUYER_DEPARTMENT\"])+\n",
    "             str(row[\"BUYER_BIRTHDAY_DATE\"])\n",
    "            ).encode()\n",
    "        ).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data['BUYER_ID'] = TX_data.apply(idBuyerCreator, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul du taux de claims par client\n",
    "\n",
    "Objectif = Créer de nouvelles features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_buyer=TX_data['IS_CLAIM'].groupby(TX_data['BUYER_ID']).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_buyer=[\"BUYER_ID\",\"Count_Buys\",\"Mean_Claims_Buys\",\"STD_Claims_Buys\",\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"]\n",
    "\n",
    "description_buyer.columns=colnames_buyer\n",
    "description_buyer.drop([\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"],axis=1,inplace=True)\n",
    "description_buyer[\"Count_Claims_Buy\"]=description_buyer[\"Mean_Claims_Buys\"]*description_buyer[\"Count_Buys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data=pd.merge(TX_data, description_buyer, on='BUYER_ID', how='outer')\n",
    "del description_buyer, colnames_buyer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'un ID par vendeur\n",
    "\n",
    "Objectif = créer une base de données vendeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idSellCreator(row):\n",
    "        return hashlib.md5(\n",
    "            (str(row[\"SELLER_COUNTRY\"])+\n",
    "             str(row[\"SELLER_DEPARTMENT\"])+\n",
    "             str(row[\"SELLER_SCORE_AVERAGE\"])\n",
    "            ).encode()\n",
    "        ).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data['SELLER_ID'] = TX_data.apply(idSellCreator, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcul du taux de claims par vendeur\n",
    "\n",
    "Objectif = Créer de nouvelles features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_sellers=TX_data['IS_CLAIM'].groupby(TX_data['SELLER_ID']).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colnames_sell=[\"SELLER_ID\",\"Count_Sells\",\"Mean_Claims_Sells\",\"STD_Claims_Sells\",\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"]\n",
    "\n",
    "description_sellers.columns=colnames_sell\n",
    "description_sellers.drop([\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"],axis=1,inplace=True)\n",
    "description_sellers[\"Count_Claims_Sells\"]=description_sellers[\"Mean_Claims_Sells\"]*description_sellers[\"Count_Sells\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data=pd.merge(TX_data, description_sellers, on='SELLER_ID', how='outer')\n",
    "del description_sellers, colnames_sell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion des bases de données\n",
    "\n",
    "Objectif = Yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_drop=[\"IS_CLAIM\",\"BUYER_ID\",\"SELLER_ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data.drop(list_to_drop,inplace=True,axis=1)\n",
    "del list_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TX_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On coupe\n",
    "\n",
    "Objectif = Créer un jeu de données train et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(TX_data, \n",
    "                                       test_size=0.3, \n",
    "                                       random_state=RANDOM_SEED, \n",
    "                                       stratify=TX_data[\"CLAIM_TYPE\"]\n",
    "                                      )\n",
    "del TX_data;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "\n",
    "Objectif = Rendre joli tout ça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(data):\n",
    "    data=data.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    # Y and X\n",
    "    Y=data[\"CLAIM_TYPE\"]\n",
    "    X=data.drop(\"CLAIM_TYPE\", axis=1,inplace=False)\n",
    "    # Exclude Objets\n",
    "    X=X.select_dtypes(exclude=['object'])\n",
    "    \n",
    "    # Work on fare\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imp = Imputer(missing_values='NaN',strategy='median', axis=1)\n",
    "    X=pd.DataFrame(imp.fit_transform(X),columns=X.columns.values)\n",
    " \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train=datapreprocess(train_set)\n",
    "X_test, Y_test=datapreprocess(test_set)\n",
    "\n",
    "del train_set, test_set;\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler\n",
    "\n",
    "Inutile pour les arbres, mais utiles pour les autres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "estimators = [('linear_pca', PCA(n_components=5)), \n",
    "                  ('kernel_pca', KernelPCA(n_components=5))]\n",
    "combined = FeatureUnion(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des variables avec une variance faible\n",
    "\n",
    "Ici, on vire tout ce qu'il y a une probabilité de 0.8 d'être la "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_vt = VarianceThreshold(threshold=(.8 * (1 - .8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection des K meilleures variables d'après le test de Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_Var = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chi_select = SelectKBest(chi2, k=Nb_Var)\n",
    "del Nb_Var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection par rapport à un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle de Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, \n",
    "                             random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfm_clf = SelectFromModel(clf)\n",
    "del clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metriques\n",
    "\n",
    "D'abord, notre métrique à nous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul l'AUC de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(truth, pred):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(truth)\n",
    "    return roc_auc_score(lb.transform(truth), lb.transform(pred), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### precision_class_AUC (pas safe), est utilisée pour le scoring de modèle (version adaptée de précédement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_class_AUC(estimator, X, y):\n",
    "    return multiclass_roc_auc_score(y, estimator.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_jobs=-1, \n",
    "                                 random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Et on pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    #('scaler', scaler),  \n",
    "    #('threshold', sel_vt), \n",
    "    #('SelectKBest', Chi_select), \n",
    "    #('reduce_dim', pca),\n",
    "    #('feature_union', combined),\n",
    "    ('feature_selection', sfm_clf),\n",
    "    ('classification', rnd_clf)\n",
    "])\n",
    "\n",
    "\n",
    "clf.fit(X_train, Y_train);\n",
    "y_pred_rf = clf.predict(X_test)\n",
    "multiclass_roc_auc_score(Y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred_rf).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(matrix):\n",
    "    \"\"\"If you prefer color and a colorbar\"\"\"\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(matrix)\n",
    "    fig.colorbar(cax)\n",
    "    \n",
    "conf_mx = confusion_matrix(Y_test, y_pred_rf)\n",
    "plot_confusion_matrix(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ATTENTION: SUPER LOOOOOOOOOOONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(n_jobs=-1,\n",
    "                         X=X_train,\n",
    "                         y=Y_train,\n",
    "                         cv=3,\n",
    "                         scoring=precision_class_AUC,\n",
    "                         estimator=rnd_clf,\n",
    "                         verbose=1)\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_leaf_nodes': [4, 8],\n",
    "          'max_depth' : [2, 4], \n",
    "          'n_estimators': list(range(10, 50, 10)),\n",
    "          'min_samples_leaf': list(range(1, 3)),\n",
    "          'min_samples_split' : list(range(2, 3)),\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs_cv = GridSearchCV(RandomForestClassifier(random_state=RANDOM_SEED, oob_score=True),\n",
    "                              params,\n",
    "                              scoring=precision_class_AUC,\n",
    "                              n_jobs=-1, \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_gs_cv.fit(X_train, Y_train)\n",
    "rf_gs_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cv_rf = rf_gs_cv.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_roc_auc_score(Y_test, y_pred_cv_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mx = confusion_matrix(Y_test, y_pred_cv_rf)\n",
    "plot_confusion_matrix(conf_mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Research of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(__doc__)\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_jobs=-1, \n",
    "                             random_state=RANDOM_SEED, \n",
    "                             verbose=0, \n",
    "                             warm_start=False,\n",
    "                            oob_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cv_long = {'bootstrap':[True, False], \n",
    "                  'max_depth':[2, 3, None], \n",
    "                  'max_features':sp_randint(1, 11), \n",
    "                  'max_leaf_nodes':sp_randint(2, 11),\n",
    "                  'min_samples_leaf':sp_randint(1, 11), \n",
    "                  'min_samples_split':sp_randint(2, 11),\n",
    "                  'n_estimators':sp_randint(5, 30), \n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "n_iter_search = 50\n",
    "random_search = RandomizedSearchCV(clf, \n",
    "                                   param_distributions=params_cv_long,\n",
    "                                   n_iter=n_iter_search,\n",
    "                                   scoring=precision_class_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "random_search.fit(X=X_train,y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
