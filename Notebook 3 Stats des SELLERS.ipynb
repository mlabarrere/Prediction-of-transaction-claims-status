{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aujourd'hui on fait de stat'\n",
    "\n",
    "\n",
    "https://challengedata.ens.fr/en/challenge/39/prediction_of_transaction_claims_status.html\n",
    "\n",
    "\n",
    "Ici, c'est le notebook dédié à la créations de stats. Donc il y a les SELLERS, et les PRODUCT TYPES qui y passent actuellement.\n",
    "\n",
    "Il aurait pu aller dans le Notebook 2, mais comme c'est assez velu, j'ai décidé de le mettre à part. Je préfère garder le 2 pour du feature simple/eco, lalala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ea25cdf7-bdbc-3cf1-0737-bc51675e3374",
    "_uuid": "fed5696c67bf55a553d6d04313a77e8c617cad99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.5 |Anaconda custom (64-bit)| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)]\n",
      "pandas version: 0.22.0\n",
      "matplotlib version: 2.2.2\n",
      "NumPy version: 1.13.3.10\n",
      "SciPy version: 1.0.1\n",
      "IPython version: 6.3.1\n",
      "scikit-learn version: 0.19.1\n",
      "seaborn version: 0.8.1\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "import seaborn as sns\n",
    "print(\"seaborn version: {}\". format(sns.__version__))\n",
    "\n",
    "#misc libraries\n",
    "import time\n",
    "import random as rnd\n",
    "import os, gc\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moi j'ai ça:\n",
    "\n",
    "Python version: 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]\n",
    "\n",
    "pandas version: 0.22.0\n",
    "\n",
    "matplotlib version: 2.1.2\n",
    "\n",
    "NumPy version: 1.12.1\n",
    "\n",
    "SciPy version: 1.0.0\n",
    "\n",
    "IPython version: 6.2.1\n",
    "\n",
    "scikit-learn version: 0.19.1\n",
    "\n",
    "seaborn version: 0.8.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de la seed pour le random\n",
    "\n",
    "Très important pour qu'on voit les mêmes choses entre nos deux ordis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42;\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "// look up into all sections and builds an automated menu //\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run \"! pip install jyquickhelper\" dans une cellule si ca ne marche pas la commande suivante\n",
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6b5dc743-15b1-aac6-405e-081def6ecca1",
    "_uuid": "2d307b99ee3d19da3c1cddf509ed179c21dec94a"
   },
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT_DIR, \"data_processed\")\n",
    "\n",
    "def load_data(file,data_path=DATA_PROCESSED, sep=','):\n",
    "    csv_path = os.path.join(data_path, file)\n",
    "    return pd.read_csv(csv_path, sep)\n",
    "\n",
    "train_df = load_data(file = \"train_notebook_2.csv\", sep=';');\n",
    "test_df = load_data(file = \"test_notebook_2.csv\", sep=';');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d6188f3-dc82-8ae6-dabd-83e28fcbf10d",
    "_uuid": "79282222056237a52bbbb1dbd831f057f1c23d69"
   },
   "source": [
    "## Analyse des types de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "ce473d29-8d19-76b8-24a4-48c217286e42",
    "_uuid": "ef106f38a00e162a80c523778af6dcc778ccc1c2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 58 columns):\n",
      "SHIPPING_MODE                 100000 non-null object\n",
      "SHIPPING_PRICE                100000 non-null int64\n",
      "WARRANTIES_FLG                100000 non-null bool\n",
      "WARRANTIES_PRICE              100000 non-null int64\n",
      "CARD_PAYMENT                  100000 non-null int64\n",
      "COUPON_PAYMENT                100000 non-null int64\n",
      "RSP_PAYMENT                   100000 non-null int64\n",
      "WALLET_PAYMENT                100000 non-null int64\n",
      "PRICECLUB_STATUS              100000 non-null int64\n",
      "REGISTRATION_DATE             100000 non-null int64\n",
      "PURCHASE_COUNT                100000 non-null int64\n",
      "BUYER_BIRTHDAY_DATE           100000 non-null float64\n",
      "BUYER_DEPARTMENT              100000 non-null int64\n",
      "BUYING_DATE                   100000 non-null int64\n",
      "SELLER_SCORE_COUNT            100000 non-null int64\n",
      "SELLER_SCORE_AVERAGE          100000 non-null float64\n",
      "SELLER_COUNTRY                100000 non-null object\n",
      "SELLER_DEPARTMENT             100000 non-null int64\n",
      "PRODUCT_TYPE                  100000 non-null object\n",
      "PRODUCT_FAMILY                100000 non-null object\n",
      "ITEM_PRICE                    100000 non-null int64\n",
      "CLAIM_TYPE                    100000 non-null object\n",
      "WARRANTY_COV_RATE             100000 non-null float64\n",
      "SELLER_COUNTRY_GINI           100000 non-null int64\n",
      "SELLER_COUNTRY_PIB            100000 non-null int64\n",
      "SELLER_COUNTRY_DISTANCE       100000 non-null int64\n",
      "BUYER_DEPARTMENT_DENSITY      100000 non-null int64\n",
      "SELLER_DEPARTMENT_DENSITY     100000 non-null int64\n",
      "BUYER_DEPARTMENT_PIB          100000 non-null int64\n",
      "SELLER_DEPARTMENT_PIB         100000 non-null int64\n",
      "BUYER_DEPARTMENT_Life_Lvl     100000 non-null int64\n",
      "SELLER_DEPARTMENT_Life_Lvl    100000 non-null int64\n",
      "BUYER_DEPARTMENT_interD       100000 non-null float64\n",
      "SELLER_DEPARTMENT_interD      100000 non-null float64\n",
      "BUYER_DEPARTMENT_Pov          100000 non-null float64\n",
      "SELLER_DEPARTMENT_Pov         100000 non-null float64\n",
      "BUYER_DEPARTMENT_min_soc      100000 non-null float64\n",
      "SELLER_DEPARTMENT_min_soc     100000 non-null float64\n",
      "BUYER_DEPARTMENT_atk          100000 non-null float64\n",
      "SELLER_DEPARTMENT_atk         100000 non-null float64\n",
      "BUYER_DEPARTMENT_cmb          100000 non-null float64\n",
      "SELLER_DEPARTMENT_cmb         100000 non-null float64\n",
      "CAC_POINTS                    100000 non-null int64\n",
      "CAC_VAR                       100000 non-null int64\n",
      "IS_HOLIDAYS                   100000 non-null int64\n",
      "IS_SALES                      100000 non-null int64\n",
      "Delivery_Quality              100000 non-null int64\n",
      "PGC_FAMILY                    100000 non-null int64\n",
      "PGC_TYPE                      100000 non-null int64\n",
      "Daily_Usage                   100000 non-null int64\n",
      "Consommable                   100000 non-null int64\n",
      "New_Techno                    100000 non-null int64\n",
      "Long_Term_Usage               100000 non-null int64\n",
      "Achat_Passion                 100000 non-null int64\n",
      "PF_W2V                        100000 non-null float64\n",
      "PT_W2V                        100000 non-null float64\n",
      "SM_W2V                        100000 non-null float64\n",
      "Type_Payment                  100000 non-null object\n",
      "dtypes: bool(1), float64(16), int64(35), object(6)\n",
      "memory usage: 43.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan d'action\n",
    "\n",
    "Idées de features engineering:\n",
    "1. faire la variable \"IS_CLAIM\"\n",
    "2. Trouver les ID des SELLERS\n",
    "3. Trouver des stats par produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable \"Is Claim\"\n",
    "\n",
    "Attention, c'est un peu dangereux d'utiliser la target variable pour faire du feature engineering.\n",
    "\n",
    "Mais ici, je veux créer des \"cartes d'identité\" par vendeur et acheteur, pour reperer les bad guys. Donc je dois connaitre le taux de rejet de chacun. Ce que je vais faire plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui prend une ligne de la BDD en entrée, et dit \"Si c'est - alors on renvoit 0, sinon 1\n",
    "def b(row):\n",
    "        return 0 if row['CLAIM_TYPE'] == '-' else 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je l'applique à la base de données\n",
    "train_df['IS_CLAIM'] = train_df.apply(b, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID par vendeur\n",
    "\n",
    "Objectif = créer une base de données vendeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "9b805f69-665a-2b2e-f31d-50d87d52865d",
    "_uuid": "817e1cf0ca1cb96c7a28bb81192d92261a8bf427"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def idSellCreator(row):\n",
    "        return hashlib.md5(\n",
    "            (str(row[\"SELLER_COUNTRY\"])+\n",
    "             str(row[\"SELLER_DEPARTMENT\"])+\n",
    "             str(row[\"SELLER_SCORE_AVERAGE\"])+\n",
    "             str(row['SELLER_SCORE_COUNT'])\n",
    "            ).encode()\n",
    "        ).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SELLER_ID'] = train_df.apply(idSellCreator, axis=1)\n",
    "test_df['SELLER_ID'] = test_df.apply(idSellCreator, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1691"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['SELLER_ID'].append(test_df['SELLER_ID'], ignore_index=True).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a 1691 identifiants uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'ID sellers dans le train : 1563\n",
      "Nombre d'ID sellers dans le test : 1568\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre d'ID sellers dans le train : {}\\nNombre d'ID sellers dans le test : {}\".format(\n",
    "    len(train_df['SELLER_ID'].unique()),\n",
    "    len(test_df['SELLER_ID'].unique()))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des taux de rejets par vendeurs\n",
    "\n",
    "Maintenant qu'on a réussi à retrouver les différents vendeurs, faut utiliser cette information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_sellers=train_df['IS_CLAIM'].groupby(train_df['SELLER_ID']).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_sell=[\"SELLER_ID\",\"Count_Sells_ID\",\"Mean_Claims_Sells_ID\",\"STD_Claims_Sells_ID\",\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"]\n",
    "\n",
    "description_sellers.columns=colnames_sell\n",
    "description_sellers.drop([\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"],axis=1,inplace=True)\n",
    "#description_sellers[\"Count_Claims_Sells_ID\"]=description_sellers[\"Mean_Claims_Sells_ID\"]*description_sellers[\"Count_Sells_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les corrélations semblent cohérentes, je pense qu'il n'y a pas d'erreur, et on peut merger ça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(description_sellers, on='SELLER_ID', how='left')\n",
    "test_df = test_df.merge(description_sellers, on='SELLER_ID', how='left')\n",
    "\n",
    "del description_sellers, colnames_sell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des stats des produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_sellers=train_df['IS_CLAIM'].groupby(train_df['PRODUCT_TYPE']).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_sell=[\"PRODUCT_TYPE\",\"Count_PRODUCT_TYPE\",\"Mean_Claims_PRODUCT_TYPE\",\"STD_Claims_PRODUCT_TYPE\",\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"]\n",
    "\n",
    "description_sellers.columns=colnames_sell\n",
    "description_sellers.drop([\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(description_sellers, on='PRODUCT_TYPE', how='left')\n",
    "test_df = test_df.merge(description_sellers, on='PRODUCT_TYPE', how='left')\n",
    "\n",
    "del description_sellers, colnames_sell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification par filler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donc on a 176 STD manquantes sur le train, mais c'est simplement car il n'y a eu qu'une vente pour le vendeur, donc un bon filler serait de le mettre à `0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.STD_Claims_Sells_ID.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste des valeurs manquantes: \n",
    "1. Count_Sells_ID : __203 (0,2%)__ valeurs manquantes\n",
    "2. Mean_Claims_Sells_ID : __203 (0,2%)__ valeurs manquantes\n",
    "3. STD_Claims_Sells_ID : __406 (0,4%)__ valeurs manquantes\n",
    "4. Count_PRODUCT_TYPE : __5__ valeurs manquantes\n",
    "5. Mean_Claims_PRODUCT_TYPE : __5__ valeurs manquantes\n",
    "6. STD_Claims_PRODUCT_TYPE : __14__ non-null float64\n",
    "\n",
    "Donc il y a maximum __203__ nouveaux vendeurs, et maximum __5__ nouveaux types de produits.\n",
    "\n",
    "Mais comme les nombres sont tout petits par rapport à la taille du test set, je pense que faire des moyenne sera suffisant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les Sells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count_Sells_ID\n",
    "count_train= train_df.Count_Sells_ID.mean()\n",
    "test_df.Count_Sells_ID.fillna(value=count_train, inplace=True)\n",
    "\n",
    "# Mean_Claims_Sells_ID\n",
    "mean_train= train_df.Mean_Claims_Sells_ID.mean()\n",
    "test_df.Mean_Claims_Sells_ID.fillna(value=mean_train, inplace=True)\n",
    "\n",
    "# Mean_Claims_Sells_ID\n",
    "std_train= train_df.STD_Claims_Sells_ID.mean()\n",
    "test_df.STD_Claims_Sells_ID.fillna(value=std_train, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les product types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count_PRODUCT_TYPE\n",
    "count_train= train_df.Count_PRODUCT_TYPE.mean()\n",
    "test_df.Count_PRODUCT_TYPE.fillna(value=count_train, inplace=True)\n",
    "\n",
    "# Mean_Claims_PRODUCT_TYPE\n",
    "mean_train= train_df.Mean_Claims_PRODUCT_TYPE.mean()\n",
    "test_df.Mean_Claims_PRODUCT_TYPE.fillna(value=mean_train, inplace=True)\n",
    "\n",
    "# STD_Claims_PRODUCT_TYPE\n",
    "std_train= train_df.STD_Claims_PRODUCT_TYPE.mean()\n",
    "train_df.STD_Claims_PRODUCT_TYPE.fillna(value=std_train, inplace=True)\n",
    "test_df.STD_Claims_PRODUCT_TYPE.fillna(value=std_train, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On oublie pas la petite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('IS_CLAIM', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On inscrit nos résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = DATA_PROCESSED+\"/train_notebook_3.csv\"\n",
    "filename_test = DATA_PROCESSED+\"/test_notebook_3.csv\"\n",
    "\n",
    "try:\n",
    "    os.remove(filename_train)\n",
    "    os.remove(filename_test)\n",
    "except:\n",
    "    pass;\n",
    "\n",
    "train_df.to_csv(filename_train, index=False, sep=\";\")\n",
    "test_df.to_csv(filename_test, index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
