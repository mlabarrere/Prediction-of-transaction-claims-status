{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aujourd'hui on se fait rouler par les mecs de l'ENS\n",
    "\n",
    "\n",
    "https://challengedata.ens.fr/en/challenge/39/prediction_of_transaction_claims_status.html\n",
    "\n",
    "\n",
    "Ici, c'est le notebook dédié à la créations de stats. Donc il y a les SELLERS, et les PRODUCT TYPES qui y passent actuellement.\n",
    "\n",
    "Il aurait pu aller dans le Notebook 2, mais comme c'est assez velu, j'ai décidé de le mettre à part. Je préfère garder le 2 pour du feature simple/eco, lalala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "ea25cdf7-bdbc-3cf1-0737-bc51675e3374",
    "_uuid": "fed5696c67bf55a553d6d04313a77e8c617cad99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]\n",
      "pandas version: 0.22.0\n",
      "matplotlib version: 2.1.2\n",
      "NumPy version: 1.12.1\n",
      "SciPy version: 1.0.0\n",
      "IPython version: 6.2.1\n",
      "scikit-learn version: 0.19.1\n",
      "seaborn version: 0.8.1\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "\n",
    "#load packages\n",
    "import sys #access to system parameters https://docs.python.org/3/library/sys.html\n",
    "print(\"Python version: {}\". format(sys.version))\n",
    "\n",
    "import pandas as pd #collection of functions for data processing and analysis modeled after R dataframes with SQL like features\n",
    "print(\"pandas version: {}\". format(pd.__version__))\n",
    "\n",
    "import matplotlib #collection of functions for scientific and publication-ready visualization\n",
    "print(\"matplotlib version: {}\". format(matplotlib.__version__))\n",
    "\n",
    "import numpy as np #foundational package for scientific computing\n",
    "print(\"NumPy version: {}\". format(np.__version__))\n",
    "\n",
    "import scipy as sp #collection of functions for scientific computing and advance mathematics\n",
    "print(\"SciPy version: {}\". format(sp.__version__)) \n",
    "\n",
    "import IPython\n",
    "from IPython import display #pretty printing of dataframes in Jupyter notebook\n",
    "print(\"IPython version: {}\". format(IPython.__version__)) \n",
    "\n",
    "import sklearn #collection of machine learning algorithms\n",
    "print(\"scikit-learn version: {}\". format(sklearn.__version__))\n",
    "\n",
    "import seaborn as sns\n",
    "print(\"seaborn version: {}\". format(sns.__version__))\n",
    "\n",
    "#misc libraries\n",
    "import time\n",
    "import random as rnd\n",
    "import os, gc\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('-'*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moi j'ai ça:\n",
    "\n",
    "Python version: 3.6.3 |Anaconda custom (64-bit)| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]\n",
    "\n",
    "pandas version: 0.22.0\n",
    "\n",
    "matplotlib version: 2.1.2\n",
    "\n",
    "NumPy version: 1.12.1\n",
    "\n",
    "SciPy version: 1.0.0\n",
    "\n",
    "IPython version: 6.2.1\n",
    "\n",
    "scikit-learn version: 0.19.1\n",
    "\n",
    "seaborn version: 0.8.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n)\n",
       "        a += \"    \";\n",
       "    return a;\n",
       "}\n",
       "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item, begin_format, end_format) {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i,t;\n",
       "    var text_menu = begin;\n",
       "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    var tags = [];\n",
       "    var main_item = 0;\n",
       "    var format_open = 0;\n",
       "    for (i = 0; i <= llast; i++)\n",
       "        tags.push(\"h\" + i);\n",
       "\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
       "\n",
       "        var child = null;\n",
       "        for(t = 0; t < tags.length; t++) {\n",
       "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
       "            if (r.length > 0) {\n",
       "child = r[0];\n",
       "break;\n",
       "            }\n",
       "        }\n",
       "        if (child == null) {\n",
       "            text_memo += \"null\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            // when converted in RST\n",
       "            href = anchors[i].id;\n",
       "            text_memo += \"#1-\" + href;\n",
       "            // passer à child suivant (le chercher)\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            // in a notebook\n",
       "            href = child.id;\n",
       "            text_memo += \"#2-\" + href;\n",
       "        }\n",
       "        else {\n",
       "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "\n",
       "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
       "\n",
       "        if ((level < lfirst) || (level > llast)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\")\n",
       "         .replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\");\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "\n",
       "        while (level < memo_level) {\n",
       "            text_menu += end_format + \"</ul>\\n\";\n",
       "            format_open -= 1;\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        if (level == lfirst) {\n",
       "            main_item += 1;\n",
       "        }\n",
       "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
       "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2);\n",
       "        text_menu += begin_format + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
       "        format_open += 1;\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += end_format + \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    text_menu += send;\n",
       "    //text_menu += \"\\n\" + text_memo;\n",
       "\n",
       "    while (format_open > 0) {\n",
       "        text_menu += end_format;\n",
       "        format_open -= 1;\n",
       "    }\n",
       "    return text_menu;\n",
       "};\n",
       "var update_menu = function() {\n",
       "    var sbegin = \"\";\n",
       "    var sformat = '<a href=\"#__HREF__\">__TITLE__</a>';\n",
       "    var send = \"\";\n",
       "    var begin_format = '<li>';\n",
       "    var end_format = '</li>';\n",
       "    var keep_item = -1;\n",
       "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item,\n",
       "       begin_format, end_format);\n",
       "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run \"! pip install jyquickhelper\" dans une cellule si ca ne marche pas la commande suivante\n",
    "from jyquickhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6b5dc743-15b1-aac6-405e-081def6ecca1",
    "_uuid": "2d307b99ee3d19da3c1cddf509ed179c21dec94a"
   },
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT_DIR, \"data_processed\")\n",
    "\n",
    "def load_data(file,data_path=DATA_PROCESSED, sep=','):\n",
    "    csv_path = os.path.join(data_path, file)\n",
    "    return pd.read_csv(csv_path, sep)\n",
    "\n",
    "train_df = load_data(file = \"train_notebook_2.csv\", sep=';');\n",
    "test_df = load_data(file = \"test_notebook_2.csv\", sep=';');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d6188f3-dc82-8ae6-dabd-83e28fcbf10d",
    "_uuid": "79282222056237a52bbbb1dbd831f057f1c23d69"
   },
   "source": [
    "## Analyse des types de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "ce473d29-8d19-76b8-24a4-48c217286e42",
    "_uuid": "ef106f38a00e162a80c523778af6dcc778ccc1c2",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 33 columns):\n",
      "SHIPPING_MODE                100000 non-null object\n",
      "SHIPPING_PRICE               100000 non-null int64\n",
      "WARRANTIES_FLG               100000 non-null bool\n",
      "WARRANTIES_PRICE             100000 non-null int64\n",
      "CARD_PAYMENT                 100000 non-null int64\n",
      "COUPON_PAYMENT               100000 non-null int64\n",
      "RSP_PAYMENT                  100000 non-null int64\n",
      "WALLET_PAYMENT               100000 non-null int64\n",
      "PRICECLUB_STATUS             100000 non-null int64\n",
      "REGISTRATION_DATE            100000 non-null int64\n",
      "PURCHASE_COUNT               100000 non-null int64\n",
      "BUYER_BIRTHDAY_DATE          100000 non-null float64\n",
      "BUYER_DEPARTMENT             100000 non-null int64\n",
      "BUYING_DATE                  100000 non-null int64\n",
      "SELLER_SCORE_COUNT           100000 non-null int64\n",
      "SELLER_SCORE_AVERAGE         100000 non-null float64\n",
      "SELLER_COUNTRY               100000 non-null object\n",
      "SELLER_DEPARTMENT            100000 non-null int64\n",
      "PRODUCT_TYPE                 100000 non-null object\n",
      "PRODUCT_FAMILY               100000 non-null object\n",
      "ITEM_PRICE                   100000 non-null int64\n",
      "CLAIM_TYPE                   100000 non-null object\n",
      "WARRANTY_COV_RATE            100000 non-null float64\n",
      "SELLER_COUNTRY_PIB           100000 non-null int64\n",
      "SELLER_COUNTRY_DISTANCE      100000 non-null int64\n",
      "BUYER_DEPARTMENT_DENSITY     100000 non-null int64\n",
      "SELLER_DEPARTMENT_DENSITY    100000 non-null int64\n",
      "BUYER_DEPARTMENT_PIB         100000 non-null int64\n",
      "SELLER_DEPARTMENT_PIB        100000 non-null int64\n",
      "CAC_POINTS                   100000 non-null int64\n",
      "CAC_VAR                      100000 non-null int64\n",
      "IS_HOLIDAYS                  100000 non-null int64\n",
      "IS_SALES                     100000 non-null int64\n",
      "dtypes: bool(1), float64(3), int64(24), object(5)\n",
      "memory usage: 24.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan d'action\n",
    "\n",
    "Idées de features engineering:\n",
    "0. faire la variable \"IS_CLAIM\"\n",
    "1. Trouver les ID des SELLERS\n",
    "2. Trouver des stats par produits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable \"Is Claim\"\n",
    "\n",
    "Attention, c'est un peu dangereux d'utiliser la target variable pour faire du feature engineering.\n",
    "\n",
    "Mais ici, je veux créer des \"cartes d'identité\" par vendeur et acheteur, pour reperer les bad guys. Donc je dois connaitre le taux de rejet de chacun. Ce que je vais faire plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui prend une ligne de la BDD en entrée, et dit \"Si c'est - alors on renvoit 0, sinon 1\n",
    "def b(row):\n",
    "        return 0 if row['CLAIM_TYPE'] == '-' else 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Je l'applique à la base de données\n",
    "train_df['IS_CLAIM'] = train_df.apply(b, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID par vendeur\n",
    "\n",
    "Objectif = créer une base de données vendeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "9b805f69-665a-2b2e-f31d-50d87d52865d",
    "_uuid": "817e1cf0ca1cb96c7a28bb81192d92261a8bf427"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "def idSellCreator(row):\n",
    "        return hashlib.md5(\n",
    "            (str(row[\"SELLER_COUNTRY\"])+\n",
    "             str(row[\"SELLER_DEPARTMENT\"])+\n",
    "             str(row[\"SELLER_SCORE_AVERAGE\"])+\n",
    "             str(row['SELLER_SCORE_COUNT'])\n",
    "            ).encode()\n",
    "        ).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SELLER_ID'] = train_df.apply(idSellCreator, axis=1)\n",
    "test_df['SELLER_ID'] = test_df.apply(idSellCreator, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1691"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['SELLER_ID'].append(test_df['SELLER_ID'], ignore_index=True).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a 1691 identifiants uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'ID sellers dans le train : 1563\n",
      "Nombre d'ID sellers dans le test : 1568\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre d'ID sellers dans le train : {}\\nNombre d'ID sellers dans le test : {}\".format(\n",
    "    len(train_df['SELLER_ID'].unique()),\n",
    "    len(test_df['SELLER_ID'].unique()))\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des taux de rejets par vendeurs\n",
    "\n",
    "Maintenant qu'on a réussi à retrouver les différents vendeurs, faut utiliser cette information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_sellers=train_df['IS_CLAIM'].groupby(train_df['SELLER_ID']).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_sell=[\"SELLER_ID\",\"Count_Sells_ID\",\"Mean_Claims_Sells_ID\",\"STD_Claims_Sells_ID\",\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"]\n",
    "\n",
    "description_sellers.columns=colnames_sell\n",
    "description_sellers.drop([\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"],axis=1,inplace=True)\n",
    "#description_sellers[\"Count_Claims_Sells_ID\"]=description_sellers[\"Mean_Claims_Sells_ID\"]*description_sellers[\"Count_Sells_ID\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les corrélations semblent cohérentes, je pense qu'il n'y a pas d'erreur, et on peut merger ça"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(description_sellers, on='SELLER_ID', how='left')\n",
    "test_df = test_df.merge(description_sellers, on='SELLER_ID', how='left')\n",
    "\n",
    "del description_sellers, colnames_sell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcément, on a pas pu tout matcher dans la base de test, donc faut remplir tout ça."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train= train_df.Count_Sells_ID.mean()\n",
    "train_df.Count_Sells_ID.fillna(value=count_train, inplace=True)\n",
    "test_df.Count_Sells_ID.fillna(value=count_train, inplace=True)\n",
    "\n",
    "mean_train= train_df.Mean_Claims_Sells_ID.mean()\n",
    "train_df.Mean_Claims_Sells_ID.fillna(value=mean_train, inplace=True)\n",
    "test_df.Mean_Claims_Sells_ID.fillna(value=mean_train, inplace=True)\n",
    "\n",
    "std_train= train_df.STD_Claims_Sells_ID.mean()\n",
    "train_df.STD_Claims_Sells_ID.fillna(value=std_train, inplace=True)\n",
    "test_df.STD_Claims_Sells_ID.fillna(value=std_train, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul des stats des produits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_sellers=train_df['IS_CLAIM'].groupby(train_df['PRODUCT_TYPE']).describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_sell=[\"PRODUCT_TYPE\",\"Count_PRODUCT_TYPE\",\"Mean_Claims_PRODUCT_TYPE\",\"STD_Claims_PRODUCT_TYPE\",\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"]\n",
    "\n",
    "description_sellers.columns=colnames_sell\n",
    "description_sellers.drop([\"t_1\",\"t_2\",\"t_3\",\"t_4\",\"t_5\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(description_sellers, on='PRODUCT_TYPE', how='left')\n",
    "test_df = test_df.merge(description_sellers, on='PRODUCT_TYPE', how='left')\n",
    "\n",
    "del description_sellers, colnames_sell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train= train_df.Count_PRODUCT_TYPE.mean()\n",
    "train_df.Count_PRODUCT_TYPE.fillna(value=count_train, inplace=True)\n",
    "test_df.Count_PRODUCT_TYPE.fillna(value=count_train, inplace=True)\n",
    "\n",
    "mean_train= train_df.Mean_Claims_PRODUCT_TYPE.mean()\n",
    "train_df.Mean_Claims_PRODUCT_TYPE.fillna(value=mean_train, inplace=True)\n",
    "test_df.Mean_Claims_PRODUCT_TYPE.fillna(value=mean_train, inplace=True)\n",
    "\n",
    "std_train= train_df.STD_Claims_PRODUCT_TYPE.mean()\n",
    "train_df.STD_Claims_PRODUCT_TYPE.fillna(value=std_train, inplace=True)\n",
    "test_df.STD_Claims_PRODUCT_TYPE.fillna(value=std_train, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = plt.cm.BrBG\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train_df.select_dtypes(exclude=\"object\").astype(float).corr(method='spearman'),\n",
    "            linewidths=0.1,\n",
    "            vmax=1.0, \n",
    "            square=True, \n",
    "            cmap=colormap, \n",
    "            linecolor='white',\n",
    "            annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = train_df.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là, je produis la liste des variables corrélées entre elles. Le seuil est inscrit à `0.6`, mais j'ai d'abord commencé à `0.9`, puis déscendu au fûr et à mesure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column WARRANTIES_FLG  correlates with:  Index(['WARRANTIES_PRICE', 'WARRANTY_COV_RATE'], dtype='object')\n",
      "column WARRANTIES_PRICE  correlates with:  Index(['WARRANTIES_FLG', 'WARRANTY_COV_RATE'], dtype='object')\n",
      "column RSP_PAYMENT  correlates with:  Index(['PRICECLUB_STATUS'], dtype='object')\n",
      "column PRICECLUB_STATUS  correlates with:  Index(['RSP_PAYMENT', 'PURCHASE_COUNT'], dtype='object')\n",
      "column PURCHASE_COUNT  correlates with:  Index(['PRICECLUB_STATUS'], dtype='object')\n",
      "column BUYER_DEPARTMENT  correlates with:  Index(['BUYER_DEPARTMENT_DENSITY'], dtype='object')\n",
      "column BUYING_DATE  correlates with:  Index(['CAC_POINTS'], dtype='object')\n",
      "column SELLER_SCORE_COUNT  correlates with:  Index(['Count_Sells_ID'], dtype='object')\n",
      "column SELLER_DEPARTMENT  correlates with:  Index(['SELLER_DEPARTMENT_DENSITY', 'SELLER_DEPARTMENT_PIB'], dtype='object')\n",
      "column WARRANTY_COV_RATE  correlates with:  Index(['WARRANTIES_FLG', 'WARRANTIES_PRICE'], dtype='object')\n",
      "column BUYER_DEPARTMENT_DENSITY  correlates with:  Index(['BUYER_DEPARTMENT', 'BUYER_DEPARTMENT_PIB'], dtype='object')\n",
      "column SELLER_DEPARTMENT_DENSITY  correlates with:  Index(['SELLER_DEPARTMENT', 'SELLER_DEPARTMENT_PIB'], dtype='object')\n",
      "column BUYER_DEPARTMENT_PIB  correlates with:  Index(['BUYER_DEPARTMENT_DENSITY'], dtype='object')\n",
      "column SELLER_DEPARTMENT_PIB  correlates with:  Index(['SELLER_DEPARTMENT', 'SELLER_DEPARTMENT_DENSITY'], dtype='object')\n",
      "column CAC_POINTS  correlates with:  Index(['BUYING_DATE', 'CAC_VAR'], dtype='object')\n",
      "column CAC_VAR  correlates with:  Index(['CAC_POINTS'], dtype='object')\n",
      "column IS_HOLIDAYS  correlates with:  Index(['IS_SALES'], dtype='object')\n",
      "column IS_SALES  correlates with:  Index(['IS_HOLIDAYS'], dtype='object')\n",
      "column Count_Sells_ID  correlates with:  Index(['SELLER_SCORE_COUNT'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "corr_level=0.5\n",
    "for names in corr_mat.index:\n",
    "    if len(corr_mat[(corr_mat.loc[names] > corr_level) & (corr_mat.loc[names].index != names)].index) > 0:\n",
    "        print('column', names,' correlates with: ',corr_mat[(corr_mat.loc[names] > corr_level) & \n",
    "                                                                     (corr_mat.loc[names].index != names)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_drop=[\n",
    "    \"WARRANTIES_FLG\",\n",
    "    \"WARRANTIES_PRICE\",\n",
    "    \"SELLER_DEPARTMENT\",\n",
    "    \"BUYER_DEPARTMENT\",\n",
    "    \"Count_Sells_ID\",\n",
    "    \"SELLER_ID\",\n",
    "    \"IS_SALES\",\n",
    "]\n",
    "\n",
    "train_df.drop(list_to_drop, axis=1, inplace=True)\n",
    "train_df.drop(\"IS_CLAIM\", axis=1, inplace=True)\n",
    "\n",
    "test_df.drop(list_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On inscrit nos résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_train = DATA_PROCESSED+\"/train.csv\"\n",
    "filename_test = DATA_PROCESSED+\"/test.csv\"\n",
    "\n",
    "try:\n",
    "    os.remove(filename_train)\n",
    "    os.remove(filename_test)\n",
    "except:\n",
    "    pass;\n",
    "\n",
    "train_df.to_csv(filename_train, index=False, sep=\";\")\n",
    "test_df.to_csv(filename_test, index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
