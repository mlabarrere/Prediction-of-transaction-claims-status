{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aujourd'hui on roule sur les mecs de l'ENS\n",
    "\n",
    "\n",
    "https://challengedata.ens.fr/en/challenge/39/prediction_of_transaction_claims_status.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports des librairies de bases\n",
    "\n",
    "On ajoutera celles qui manquent au fur et à mesure de nos besoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition de la seed pour le random\n",
    "\n",
    "Très important pour qu'on voit les mêmes choses entre nos deux ordis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42;\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des paramètres pour Matplot\n",
    "\n",
    "Rien de bien intéréssant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set des variables globales\n",
    "\n",
    "Attention, je n'utilise les variables globales pour la gestion des fichiers. Sinon, c'est mort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "DATA_PROCESSED = os.path.join(PROJECT_ROOT_DIR, \"data_processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonction pour load les libraires\n",
    "\n",
    "En vrai, on a juste besoin de pd.read_csv, mais c'était pour faire joli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file,data_path=DATA_PROCESSED, sep=';'):\n",
    "    csv_path = os.path.join(data_path, file)\n",
    "    return pd.read_csv(csv_path, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On load les jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data = load_data(file = \"train.csv\");\n",
    "TEST_DATA = load_data(file = \"test.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS = pd.DataFrame({'ID' : []})\n",
    "RESULTS[\"ID\"]=TEST_DATA[\"ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA.drop(\"ID\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TX_data.drop(['CARD_PAYMENT','COUPON_PAYMENT','RSP_PAYMENT','WALLET_PAYMENT'], axis = 1, inplace = True)\n",
    "TEST_DATA.drop(['CARD_PAYMENT','COUPON_PAYMENT','RSP_PAYMENT','WALLET_PAYMENT'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 57 columns):\n",
      "SHIPPING_MODE                 100000 non-null object\n",
      "SHIPPING_PRICE                100000 non-null int64\n",
      "WARRANTIES_FLG                100000 non-null bool\n",
      "WARRANTIES_PRICE              100000 non-null int64\n",
      "PRICECLUB_STATUS              100000 non-null int64\n",
      "REGISTRATION_DATE             100000 non-null int64\n",
      "PURCHASE_COUNT                100000 non-null int64\n",
      "BUYER_BIRTHDAY_DATE           100000 non-null float64\n",
      "BUYER_DEPARTMENT              100000 non-null int64\n",
      "BUYING_DATE                   100000 non-null int64\n",
      "SELLER_SCORE_COUNT            100000 non-null int64\n",
      "SELLER_SCORE_AVERAGE          100000 non-null float64\n",
      "SELLER_COUNTRY                100000 non-null object\n",
      "SELLER_DEPARTMENT             100000 non-null int64\n",
      "PRODUCT_TYPE                  100000 non-null object\n",
      "PRODUCT_FAMILY                100000 non-null object\n",
      "ITEM_PRICE                    100000 non-null int64\n",
      "CLAIM_TYPE                    100000 non-null object\n",
      "WARRANTY_COV_RATE             100000 non-null float64\n",
      "SELLER_COUNTRY_GINI           100000 non-null int64\n",
      "SELLER_COUNTRY_PIB            100000 non-null int64\n",
      "SELLER_COUNTRY_DISTANCE       100000 non-null int64\n",
      "BUYER_DEPARTMENT_DENSITY      100000 non-null int64\n",
      "SELLER_DEPARTMENT_DENSITY     100000 non-null int64\n",
      "BUYER_DEPARTMENT_PIB          100000 non-null int64\n",
      "SELLER_DEPARTMENT_PIB         100000 non-null int64\n",
      "BUYER_DEPARTMENT_Life_Lvl     100000 non-null int64\n",
      "SELLER_DEPARTMENT_Life_Lvl    100000 non-null int64\n",
      "BUYER_DEPARTMENT_interD       100000 non-null float64\n",
      "SELLER_DEPARTMENT_interD      100000 non-null float64\n",
      "BUYER_DEPARTMENT_Pov          100000 non-null float64\n",
      "SELLER_DEPARTMENT_Pov         100000 non-null float64\n",
      "BUYER_DEPARTMENT_min_soc      100000 non-null float64\n",
      "SELLER_DEPARTMENT_min_soc     100000 non-null float64\n",
      "BUYER_DEPARTMENT_atk          100000 non-null float64\n",
      "SELLER_DEPARTMENT_atk         100000 non-null float64\n",
      "BUYER_DEPARTMENT_cmb          100000 non-null float64\n",
      "SELLER_DEPARTMENT_cmb         100000 non-null float64\n",
      "CAC_POINTS                    100000 non-null int64\n",
      "CAC_VAR                       100000 non-null int64\n",
      "IS_HOLIDAYS                   100000 non-null int64\n",
      "IS_SALES                      100000 non-null int64\n",
      "Delivery_Quality              100000 non-null int64\n",
      "PGC_FAMILY                    100000 non-null int64\n",
      "PGC_TYPE                      100000 non-null int64\n",
      "Daily_Usage                   100000 non-null int64\n",
      "Consommable                   100000 non-null int64\n",
      "New_Techno                    100000 non-null int64\n",
      "Long_Term_Usage               100000 non-null int64\n",
      "Achat_Passion                 100000 non-null int64\n",
      "SELLER_ID                     100000 non-null object\n",
      "Count_Sells_ID                100000 non-null float64\n",
      "Mean_Claims_Sells_ID          100000 non-null float64\n",
      "STD_Claims_Sells_ID           100000 non-null float64\n",
      "Count_PRODUCT_TYPE            100000 non-null float64\n",
      "Mean_Claims_PRODUCT_TYPE      100000 non-null float64\n",
      "STD_Claims_PRODUCT_TYPE       100000 non-null float64\n",
      "dtypes: bool(1), float64(19), int64(31), object(6)\n",
      "memory usage: 42.8+ MB\n"
     ]
    }
   ],
   "source": [
    "TX_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jointure entre les X et Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(data):\n",
    "    data=data.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    # Y and X\n",
    "    try :\n",
    "        Y=data[\"CLAIM_TYPE\"]\n",
    "        X=data.drop(\"CLAIM_TYPE\", axis=1,inplace=False)\n",
    "    except:\n",
    "        Y=0\n",
    "        X=data\n",
    "    # Exclude Objets\n",
    "    X=X.select_dtypes(exclude=['object'])\n",
    "    \n",
    "    # Work on fare\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imp = Imputer(missing_values='NaN',strategy='median', axis=1)\n",
    "    X=pd.DataFrame(imp.fit_transform(X),columns=X.columns.values)\n",
    " \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, Y_train = datapreprocess(TX_data)\n",
    "TEST_DATA, _ = datapreprocess(TEST_DATA)\n",
    "\n",
    "#del TX_data;\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Core XGBoost Library VS scikit-learn API\n",
    "\n",
    "Models can be trained in two different ways:\n",
    "\n",
    "1. Directly using the core library – this is closer to the implementation of the caret-package in R\n",
    "2. Using the scikit-learn API – this means that the models are implemented in a way that lets the scikit package recognize it as one of it’s own models.\n",
    "\n",
    "Nous, on va travailler avec l'API de Sklearn, c'est pas optimisé mais plus simple. De toute façon, j'arrive pas à utiliser le Core, a cause des DMatrix qui veulent que des numerics en entrées\n",
    "\n",
    "Doc des paramètres: https://github.com/dmlc/xgboost/blob/master/doc/parameter.md\n",
    "\n",
    "Doc sur le tunning : https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weight_arr = compute_sample_weight(class_weight='balanced', y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_XGB={\n",
    "# General Parameters -  the overall functioning\n",
    "    'booster':'gbtree',\n",
    "    'silent':0,\n",
    "    #'nthread':4, # Je le commente, puisque il détecte automatiquement le nombre de cores qu'il peut utiliser.\n",
    "    'n_estimators' : 1000,\n",
    "    \n",
    "# Booster Parameters - the individual booster (tree/regression) at each step\n",
    "    'learning_rate' : 0.09,\n",
    "    'min_child_weight' : 1, #A smaller value is chosen because it is a highly imbalanced class problem and leaf nodes can have smaller size groups.\n",
    "    'max_depth' : 4,\n",
    "    #'max_leaf_nodes':None, #If this is defined, GBM will ignore max_depth.\n",
    "    'gamma' : 0.3,\n",
    "    'max_delta_step':10, #it might help in logistic regression when class is extremely imbalanced/ 1-10 might help control the update\n",
    "    'subsample' : 0.7,\n",
    "    'colsample_bytree' : 0.8,\n",
    "    'colsample_bylevel':1, #default\n",
    "    'reg_lambda' : 1, #default\n",
    "    'reg_alpha':0,\n",
    "    'scale_pos_weight' : sample_weight_arr,\n",
    "\n",
    "# Learning Task Parameters -  the optimization performed\n",
    "    'objective' : 'multi:softmax', # you also need to set an additional num_class (number of classes)\n",
    "    'num_class' : len(Y_train.unique()),\n",
    "    'eval_metric':\"auc\",\n",
    "    'seed' : RANDOM_SEED,\n",
    "    'random_state':RANDOM_SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(**params_XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0.3,\n",
       "       learning_rate=0.09, max_delta_step=10, max_depth=4,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, n_jobs=1,\n",
       "       nthread=None, num_class=8, objective='multi:softprob',\n",
       "       random_state=42, reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=array([ 2.11077,  0.25012, ...,  1.78546,  0.25012]),\n",
       "       seed=42, silent=0, subsample=0.7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(\n",
    "    X=X_train, \n",
    "    y=Y_train, \n",
    "    sample_weight=sample_weight_arr, \n",
    "    eval_set=None, \n",
    "    eval_metric='auc', \n",
    "    early_stopping_rounds=None, \n",
    "    verbose=True, \n",
    "    xgb_model=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = xgb_clf.predict(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS[\"CLAIM_TYPE\"] = pd.DataFrame(y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CLAIM_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>SELLER_CANCEL_POSTERIORI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>SELLER_CANCEL_POSTERIORI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>DAMAGED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID                CLAIM_TYPE\n",
       "0  100000  SELLER_CANCEL_POSTERIORI\n",
       "1  100001                WITHDRAWAL\n",
       "2  100002  SELLER_CANCEL_POSTERIORI\n",
       "3  100003                         -\n",
       "4  100004                   DAMAGED"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = DATA_PROCESSED+\"/submission_XBG_3.csv\"\n",
    "\n",
    "RESULTS.to_csv(filename, index=False, sep=\";\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
